[
   "Moscow Data Science Major August 2019: программа и регистрация",
   "\r\nUPD: Присоединяйтесь к онлайн-трансляции:\n\nАтриум\nПереговорная 1\nКинозал\n\n\r\n31 августа 2019г. Mail.ru Group и сообщество Open Data Science приглашают на Moscow Data Science Major. Это как Data Fest, только мини. Событие состоит из 8 тематических блоков докладов, 1 ML-тренировки и 8 часов ударной порции нетворкинга и знакомств. Знакомьтесь с программой и регистрируйтесь! Вход на событие бесплатный, по одобренной регистрации. Регистрация закрывается в 28 августа в 17:00.\n\r\nДоклады на Moscow Data Science Major пройдут в три потока. В таблице вы найдете сетку с расписанием, а ниже — описания докладов.\n\nЗал Атриум\n\n\nВремя\nСекция\nТемы докладов \nДокладчик\n\n\n10:00 – 11:00\nРегистрация\n\n\n11:00 – 11:30\nПриветственное слово\n\n\n11:30 – 13:00\nSysML\nEnd-to-End Production: на примере дефектовки колодок и бандажей тележек локомотивов с помощью CV\n Александр Дончук\n\n\nДавай останемся друзьями — или как устроен раздел Возможно Вы Знакомы в Одноклассниках\nЕвгений Малютин\n\n\nСуровая действительность товарных рекомендаций бытовой техники\nВладимир Литвинюк\n\n\n13:00 – 13:30\nПерерыв\n\n\n13:30 – 15:00\nNLP\nПромышленная эксплуатация BERT в задачах классификации и поиска\nДенис Антюхов\n\n\nВытаскивание товаров из платежек\nАндрей Ахметов\n\n\nNER: как мы учили Почту выделять именованные сущности\nМихаил Баранов\n\n\nПереобучение? Не думаю. Как машинное обучение работает в новостном агентстве\nАндрей Коломиец\n\n\nSentence-level pretraining\nБорис Зубарев\n\n\n15:00 – 15:30\nПерерыв\n\n\n15:30 – 17:00\nFail/cess story\nМоделирование продаж\nМаксим Павлов\n\n\nРанжирование ленты ВКонтакте: офлайн валидация моделей\nДанила Савенков\n\n\nКак мы не запилили динамическое ценообразование в большом е-коме\nПавел Мягких и Евгений Лимаренко\n\n\nМультимодальное распознавание эмоций\nАндрей Беляев\n\n\n17:00\nЗавершение программы\n\n\nСекция SysML\n«End-to-End Production: на примере дефектовки колодок и бандажей тележек локомотивов с помощью CV», Александр Дончук\r\nВ начале 2019 года компания Aurorai сделала опытный образец системы поиска дефектов в тормозных колодках локомотивов, а сейчас у нас уже готово серийный образец. Я расскажу, как происходил процесс разработки, с какими проблемами мы столкнулись и как их решали — in depths.\n\n«Давай останемся друзьями — или как устроен раздел Возможно Вы Знакомы в Одноклассниках», Малютин Евгений\r\nВозможно вы знакомы, ВВЗ, PYMK, people you may know — та самая часть социальной сети, в которой находятся люди, которых вы хотели бы не знать. Рассказ про то как устроен ВВЗ в Одноклассниках и как мы помогаем пользователям не остаться одним в этом холодном мире с помощью машинного обучения. В программе:\n\n\nML\nБольшие графы\nТяжелые вычисления\nГрязные трюки \nSocial Network Analysis\n\n«Суровая действительность товарных рекомендаций бытовой техники», Владимир Литвинюк \r\nКатегория бытовой техники и электроники имеет свою специфику с точки зрения постановки задачи рекомендаций: низкая частота и слабая связанность покупок, разнообразие категорий, невысокая доля импульсных покупок/покупок, связанных с интересами и стилем жизни. В докладе я расскажу, какие ограничения с точки зрения постановки задачи и использования алгоритмов это на нас накладывает, какие бизнес-сценарии взаимодействия с клиентом мы охватываем, какие данные и алгоритмы используем, где и почему уместно и эффективно использовать ML, где мы обходимся более простыми техниками.\n\nСекция NLP\n«Промышленная эксплуатация BERT в задачах классификации и поиска», Денис Антюхов\r\nРасскажу о том как мы применяем BERT для широкого спектра задач NLP. В программе: BERT как сервис, деплой и горизонтальное масштабирование, case studies: анализ тональности, NER, DSSM для QA.\n\n«Вытаскивание товаров из платежек», Андрей Ахметов\r\nЗадача: Платежные документы содержат фразы описания товаров и услуг, которые продают и покупают. Нужно эту инфу преобразовать в таблицу [ID компании, список фраз].\n\r\nРешение: Используем Томита-парсер, NER модель, bigARTM, кластеризацию чтобы задачу решить.\n\n«NER: как мы учили Почту выделять именованные сущности», Михаил Баранов\r\nКак часто вам приходится искать в ящике письма о заказах в интернет-магазине, а затем просматривать их, пытаясь найти информацию: что это за заказ, где он сейчас находится, когда и где его можно получить? \n\r\nМы научили Почту делать это за вас. Модель машинного обучения распознает такие именованные сущности, как статус заказа, его номер, дату доставки и т.п., после чего вся важная информация о заказе отображается в шапке письма.\n\r\nИз доклада вы узнаете:\n\n\nчто зажгло — нейронки или бустинг;\nкак измерить качество на потоке, не имея доступа к пользовательским данным;\nна какие грабли мы наступили в процессе, и как с ними справились;\nи многое другое.\n\n«Переобучение? Не думаю. Как машинное обучение работает в новостном агентстве», Андрей Коломиец\r\nХотел бы рассказать про несколько решенных нами задач: автоматическую модерацию комментариев, тегирование новостей, рекомендации новостей (с точки зрения NLP). При этом используются самые разнообразные инструменты: от BERT до моделей на правилах. Описанные проекты внедрены в продакшн и приносят пользу с точки зрения бизнеса (уменьшение рутинного труда модераторов и редакторов, повышение посещаемости, поисковая оптимизация).\n\n«Sentence-level pretraining», Борис Зубарев\r\nРасскажу о том, как мне удалось повысить f1 на 7 пунктов в многоклассовой классификации на 5-ти тысячах размеченных примерах за счет использования предтренировки и чего-то среднего между аугментациями и proxy labelling. Как и многие, я не могу использовать большие модели типа BERT для инференса, примеров мало и tf-idf + логистическая регрессия выглядит довольно неплохим вариантом пока не добыты еще данные. Но когда тебе важны метрики прямо сейчас можно найти выход получше, особенно если есть неразмеченные данные, итоговая модель evolved transformer + inception и она влезла в 20 мс инференса на CPU. Также на ACL была представлена статья с похожей идеей, но с меньшим количеством шагов в пайплайне, которые мне докинули (как раз аугментации): How to Get Past Sesame Street: Sentence-Level Pretraining Beyond Language Modeling?\n\r\nРасскажу также хаки как лучше заводить такой пайплайн, какие есть сложности, какие есть методы аугментации помимо back-translation и как добавлять новые данные из другой задачи и другого домена, например сентимент.\n\nСекция Fail/cess story\n«Моделирование продаж», Максим Павлов\r\nПрогнозирование спроса в ритейле (на примере X5).\n\n«Ранжирование ленты ВКонтакте: офлайн валидация моделей», Данила Савенков\r\nПоговорим о ранжировании умной ленты ВКонтакте. Обсудим постановку задачи, ключевые метрики и нюансы в работе оффлайн модели.\n\n«Как мы не запилили динамическое ценообразование в большом е-коме», Павел Мягких, Евгений Лимаренко\r\nИстория о том, как мы запускали проект по динамическому ценообразованию, с какими проблемами столкнулись, как мы превозмогали, и чем в итоге эта сказка закончилась.\n\n«Мультимодальное распознавание эмоций», Андрей Беляев\r\nРазличие между мультимодальным и уномодальным определением эмоций. Проблемы данных для мультимодального определения эмоций. Модальности для работы: лицо, голос, тело, текст, пульс. Объединение модальностей.\n\n1 переговорная\n\n\nВремя\nСекция\nТема доклада\nДокладчик\n\n\n10:00 – 11:00\nРегистрация\n\n\n11:00 – 11:30\nПриветственное слово\n\n\n11:30 – 13:00\nML Trainings\nIce Vision Hackathon\n\nАзат Давлетшин\n\n\n\nKDD 2019 Policy Learning for Malaria Control\n\nВлад Шах-Назаров\n\n\n\nЧемпионат по машинному обучению и анализу данных — ML Bootcamp 9\n\nАлександр Ничипоренко\n\n\n\n13:00 – 13:30\nПерерыв\n\n\n13:30 – 15:00\nML4IR\nМир глазами нейросетей\nДанила Байгушев и Михаил Белозеров\n\n\nОбзор трендов рекомендательных систем от Пульса\nАндрей Мурашев\n\n\nНейро-машинный перевод в вопросно-ответных системах\nФедор Федоренко\n\n\n15:00 – 15:30\nПерерыв\n\n\n15:30 – 17:00\nPyData\nКак ухаживать за пандами\nНиколай Марков\n\n\nФишки AutoML\nДенис Воротынцев\n\n\nPyData Puzzlers\nПётр Ермаков\n\n\n17:00\nЗавершение программы\n\n\nСекция ML trainings\n«Ice Vision Hacathon», Азат Давлетшин\r\nВ докладе я расскажу про то, как мы победили в хакатоне IceVision, на котором нужно было детектировать и классифицировать дорожные знаки на видеопоследовательностях. Ключевые характеристики датасета и конкурса: мелкие объекты на высоком разрешении, сложные условия съемки, сильный дисбаланс классов, небольшая тренировочная выборка, жесткие ограничения по железу и производительности решения.\n\n«KDD 2019 Policy Learning for Malaria Control», Влад Шах-Назаров\r\nРасскажу про свой опыт участия в треке по обучению с подкреплением KDD Cup 2019. Какая была задача, какой подход позволил занять высокое место и почему простой random search — это competitive approach to RL и на соревнованиях.\n\n«Чемпионат по машинному обучению и анализу данных – ML Boot Camp 9», Александр Ничипоренко\r\nДоклад о решении, занявшем первое место: речь пойдет о задаче детектирования объектов на изображениях (изображений в датасете не было), разметке, метрике, критерии минмакс, несработавших идеях и о том, что в итоге сработало.\n\nСекция ML4IR\n«Мир глазами нейросетей», Данила Байгушев и Михаил Белозеров\r\nДоклад освещает проблему интерпретируемости предсказаний нейросетей. Расскажем про современные (и не очень) подходы к анализу обученных нейросетей, а также обсудим, похоже ли их “видение мира” на наше, и как понимание их устройства позволяет находить способы обмана моделей.\n\n«Обзор трендов рекомендательных систем от Пульса», Андрей Мурашев\r\nВ рамках доклада будет сделан обзор современных трендов в рекомендательных системах на основании последней конференции RecSys. Какие методы еще развиваются, какие обрели новую жизнь и на что делают ставку в будущем рекомендаций. Расскажу, что из этого уже используется в продуктах Пульса, и что мы планируем применять.\n\n«Нейро-машинный перевод в вопросно-ответных системах», Федор Федоренко\r\nС появлением огромного количества голосовых помощников, задача построения вопросно-ответной системы становится всё более и более актуальной. Одной из главных задач таких систем является нахождение документов, релевантных вопросу. В докладе поговорим о том, как мы делали такую систему на основе Ответов Mail.Ru, и как на помощь классическим алгоритмам извлечения информации пришёл нейромашинный перевод.\n\nСекция PyData\n«Как ухаживать за пандами», Николай Марков\r\nPandas — отличная базовая библиотека для работы с данными, включая очистку, генерацию новых фич и интеграцию с инструментами машинного обучения. Проблема в том, что в ней, несмотря на кажущуюся простоту, есть разные тонкости, а также готовые обертки, которые могут сильно облегчить жизнь, если о них знать. Попробуем вникнуть?\n\n«Фишки AutoML», Денис Воротынцев\r\nСовременные AutoML модели показывают хорошие результаты в соревнованиях Kaggle, создавая точные модели за малое время. Каким образом они это делают? В ходе этого доклада будут рассмотрены out of the box методы, применяемые для автоматической генерации и отбора фичей, подбора моделей и тюнинг гиперпараметров, которые могут применяться в data science пайплайне для увеличения скоров при меньших вложенных человеко-часах.\n\n«PyData Puzzlers», Пётр Ермаков\r\nРабота с данными в Python не предвещает беды и сюрпризов. Да и какие тут еще пазлеры? Нетривиальное поведение возможно только в Java. Но не тут то было! В интерактивном формате вместе с аудиторией мы откроем новые возможности выстрелить себе в ногу и облажаться в Python-е для Data Science.\n\nКинозал\n\n\nВремя\nСекция\nТема доклада\nДокладчик\n\n\n10:00 – 11:00\nРегистрация\n\n\n11:00 – 11:30\nПриветственное слово\n\n\n11:30 – 13:00\nA/B testing\nКак мы ускорили А/Б тесты в Яндекс Советнике в 10/100 раз\nНерсес Багиян\n\n\nРекурсивная оценка разнородности причинных эффектов в субпопуляциях при A/B\nАлексей Мясников\n\n\nМетодология А/Б тестов и пост-анализа в офлайн ритейле\nАлександр Сахнов\n\n\n13:00 – 13:30\nПерерыв\n\n\n13:30 – 15:00\nDS 4 Life\nСистема контроля качества медицинской документации\nВалерия Можарова\n\n\nЭмоции города: анализ качества городской среды с помощью PPGIS\nАлександра Ненько\n\n\nВычислительное прогнозирование психометрик пользователя на основе его цифрового следа в социальных сетях\nИрина Деева\n\n\nЭмоциональный пульс школы: использование данных ВКонтакте для изучения психологического благополучия учащихся\nИван Смирнов\n\n\n15:00 – 15:30\nПерерыв\n\n\n15:30 – 17:00\nSummer ML Conf\n\nICML 2019 Report\nСергей Свиридов\n\n\nACL\nВалентин Малых\n\n\nHighlights and trends CVPR-2019\nСергей Алямкин\n\n\nSIGIR 2019\nМаксим Павлов\n\n\n17:00\nЗавершение программы\n\n\nСекция A/B testing\n«Как мы ускорили А/Б тесты в Яндекс Советнике в 10/100 раз», Нерсес Багиян\r\nПеред нами встала задача ускорить А/Б тесты в сто раз и мы вышли за пределы дозволенного. Линеаризация, перевзвешивание, машинное обучение и даже Баес во славу А/Б.\n\n«Рекурсивная оценка разнородности причинных эффектов в субпопуляциях при A/B», Алексей Мясников\r\nРассматривается data-driven подход к разделению данных на субпопуляции, отличающиеся величиной наблюдаемого эффекта\". По сути рассматривается новая реализация regression trees, умеющая создавать аккуратные доверительные интервалы (помимо других стат. методов).\n\n«Методология А/Б тестов и пост-анализа в офлайн ритейле», Александр Сахнов\r\nВ офлайне тоже делают А/Б и хорошо когда можно заранее разбить на группу А и группу Б. Такая роскошь дозволена не всегда. Расскажем что делаем в каждом из случаев, от бакетных методов, до баесовских структурных временных рядов.\n\nСекция DS 4 Life\n«Эмоции города: анализ качества городской среды с помощью PPGIS», Александра Ненько\n\n«Вычислительное прогнозирование психометрик пользователя на основе его цифрового следа в социальных сетях», Ирина Деева\r\nЛюди регулярно оставляют достаточно своих данных в социальных сетях и на разных сайтах, формируя таким образом свой уникальный цифровой след. Этот цифровой след может быть рассмотрен как база к созданию цифровой сущности человека в гиперпространстве социальных медиа. Однако человек — это сложная система; следовательно, модель цифрового объекта должна быть многомасштабной. В этом докладе мы рассмотрим связь такой слабо формализуемой стороны пользователя, как его психометрические показатели, и его цифрового следа на сайтах социальных сетей. Будет представлено описание серии экспериментов по прогнозированию психометрик, основанном на данных из двух социальных сетей (Facebook и Vkontakte), в ходе которых сравнивались два подхода к прогнозированию: многомерное прогнозирование, когда все психометрические показатели прогнозируются одновременно, и одномерные модели для каждой черты личности. Попробуем сравнить результаты этих прогнозирований и наконец ответим на вопрос, можно ли понять, кто скрывается за профилем человека в социальных сетях?\n\n«Эмоциональный пульс школы: использование данных ВКонтакте для изучения психологического благополучия учащихся», Иван Смирнов\r\nИсследования образования традиционно фокусируются на академической успеваемости, зачастую игнорируя психологическое благополучие учащихся. Отчасти это связано с тем, что психологическое благополучие и факторы, с ним связанные, сложно изучать, используя традиционные методы. В докладе будет рассказано о том, как данные из соц.сетей и методы машинного обучения могут помочь преодолеть эти ограничения.\n\nСекция Summer ML conf\n«ICML 2019 Report», Сергей Свиридов\r\nЯ расскажу о том, как проходила конференция ICML 2019 в Long Beach, CA, USA, о трендах конференции и самых интересных (и не только) статьях, представленных на конференции с особым акцентом на работы в области обучения с подкреплением.\n\n«ACL», Валентин Малых\r\nЯ расскажу о поездке на крупнейшую конференцию по обработке естесственного языка — ACL, прошедшую во Флоренции месяц назад. Что актуально сейчас в NLP и обработке речи, машинном переводе и других горячих темах, самое свежее с ACL.\n\n«Highlights and trends CVPR-2019», Сергей Алямкин\r\nВ докладе будут освещены основные тренды развития алгоритмов компьютерного зрения с конференции CVPR-2019. В силу своих профессиональных интересов акцент сделаю на свежих идеях в domain adaptation, SOTA в распознавании лиц, сделаю небольшой экскурс в тематику Convolution Graph Neural Networks и расскажу про ряд других прикладных работ, вызвавшим у меня интерес.\n\nВход на событие бесплатный, по одобренной регистрации. Регистрация закрывается в 28 августа в 17:00.\n\r\nСбор участников и регистрация: 10:00.\r\nНачало докладов: 11:00.\n\r\nАдрес: г. Москва, м. «Аэропорт», Ленинградский пр-т, д. 39, стр. 79.\n\r\nПрисоединяйтесь к онлайн-трансляции:\n\nАтриум\nПереговорная 1\nКинозал\n "
]